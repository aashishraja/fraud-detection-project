{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d7c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# --- 1. Core Data Handling & System Tools ---\n",
    "# 'os' is often used for path construction (e.g., reading your CSV from the 'data' folder)\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp # Renaming to 'sp' for generic scientific functions\n",
    "\n",
    "# For progress bars (tqdm is available)\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "# --- 2. Visualization Libraries ---\n",
    "# All core visualization tools are available\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# --- 3. Machine Learning & Modeling (scikit-learn is available) ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Metrics are crucial for classification problems like fraud detection\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Import common models you might use (replace/add as needed)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "\n",
    "# For model interpretability\n",
    "import shap\n",
    "\n",
    "\n",
    "# Define project root dynamically\n",
    "PROJECT_ROOT = Path.cwd().parent if \"notebooks\" in Path.cwd().parts else Path.cwd()\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"fraud_detection_dataset.csv\"\n",
    "\n",
    "# Read CSV\n",
    "fulldf = pd.read_csv(DATA_PATH)\n",
    "fulldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0575726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "\n",
    "# 1 - Check for Missing Values\n",
    "\n",
    "null_vals = fulldf.isnull().sum()\n",
    "\n",
    "\n",
    "# 2 - Date Standarisation \n",
    "fulldf['timestamp'] = pd.to_datetime(fulldf['timestamp'], errors='coerce')\n",
    "int(fulldf['timestamp'].isna().sum()) #as the number is = 0 we can be certain that all dates have been standardised\n",
    "\n",
    "# 3 - Validation of fraud label\n",
    "fulldf['is_fraud'].value_counts() # result shows that there are 1,000,000 fraud and 1,000,000 not fraud transactions\n",
    "\n",
    "# In addition all data types have been validated via the use of fulldf.info\n",
    "fulldf.dtypes\n",
    "\n",
    "# No duplicate transaction - validated by creating compound key with timestamp and user_id \n",
    "bool(fulldf[['user_id', 'timestamp']].duplicated().any())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fraud-detection)",
   "language": "python",
   "name": "fraud-detection"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
